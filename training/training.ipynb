{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "qmtvtwjntsbbjk2o7tka2m",
    "id": "4bJPhFc1h535"
   },
   "source": [
    "Подготовка среды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "cellId": "sia5d1gg8nmasj3pd3bn5o",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15039,
     "status": "ok",
     "timestamp": 1666563805979,
     "user": {
      "displayName": "Ninja Of The Midnight",
      "userId": "05843998480307648924"
     },
     "user_tz": -180
    },
    "id": "SkORqJYiS2fZ",
    "outputId": "13fa777d-910d-484b-8569-1e264771b7d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyarrow in /home/jupyter/.local/lib/python3.8/site-packages (9.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /kernel/fallback/lib/python3.8/site-packages (from pyarrow) (1.19.4)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /kernel/lib/python3.8/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: requests in /kernel/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (5.3.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /kernel/fallback/lib/python3.8/site-packages (from transformers) (1.19.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/jupyter/.local/lib/python3.8/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.8/dist-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/jupyter/.local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /kernel/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /kernel/lib/python3.8/site-packages (from requests->transformers) (1.26.12)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /kernel/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /kernel/lib/python3.8/site-packages (from requests->transformers) (2022.9.24)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /kernel/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: six in /kernel/lib/python3.8/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (8.0.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (1.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: datasets in /home/jupyter/.local/lib/python3.8/site-packages (2.6.1)\n",
      "Requirement already satisfied: dill<0.3.6 in /home/jupyter/.local/lib/python3.8/site-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: multiprocess in /home/jupyter/.local/lib/python3.8/site-packages (from datasets) (0.70.13)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /home/jupyter/.local/lib/python3.8/site-packages (from datasets) (9.0.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (0.25.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /kernel/lib/python3.8/site-packages (from datasets) (2.25.1)\n",
      "Requirement already satisfied: packaging in /kernel/lib/python3.8/site-packages (from datasets) (20.9)\n",
      "Requirement already satisfied: xxhash in /kernel/fallback/lib/python3.8/site-packages (from datasets) (2.0.0)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.10.15)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/jupyter/.local/lib/python3.8/site-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.2.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (5.3.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2021.11.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /kernel/fallback/lib/python3.8/site-packages (from datasets) (1.19.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.4.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/jupyter/.local/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /kernel/lib/python3.8/site-packages (from packaging->datasets) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /kernel/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2022.9.24)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /kernel/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /kernel/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /kernel/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.12)\n",
      "Requirement already satisfied: six in /kernel/lib/python3.8/site-packages (from responses<0.19->datasets) (1.16.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (5.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /kernel/lib/python3.8/site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.0.9)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /kernel/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.15.0-py3-none-any.whl (191 kB)\n",
      "     |████████████████████████████████| 191 kB 1.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /kernel/lib/python3.8/site-packages (from accelerate) (20.9)\n",
      "Requirement already satisfied: torch>=1.4.0 in /home/jupyter/.local/lib/python3.8/site-packages (from accelerate) (1.12.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /kernel/fallback/lib/python3.8/site-packages (from accelerate) (1.19.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from accelerate) (5.3.1)\n",
      "Requirement already satisfied: psutil in /kernel/lib/python3.8/site-packages (from accelerate) (5.7.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /kernel/lib/python3.8/site-packages (from packaging>=20.0->accelerate) (2.4.7)\n",
      "Requirement already satisfied: typing-extensions in /home/jupyter/.local/lib/python3.8/site-packages (from torch>=1.4.0->accelerate) (4.4.0)\n",
      "Installing collected packages: accelerate\n",
      "\u001b[33m  WARNING: The scripts accelerate, accelerate-config and accelerate-launch are installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed accelerate-0.15.0\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "%pip install pyarrow\n",
    "%pip install transformers\n",
    "%pip install datasets\n",
    "%pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "cellId": "3yzcx6f3elw6arus18eqm7",
    "executionInfo": {
     "elapsed": 8524,
     "status": "ok",
     "timestamp": 1666563814496,
     "user": {
      "displayName": "Ninja Of The Midnight",
      "userId": "05843998480307648924"
     },
     "user_tz": -180
    },
    "id": "wsoTA1D5BTS-"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextDataset, DataCollatorForLanguageModeling\n",
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoConfig\n",
    "from transformers import utils\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from datasets import load_dataset, Dataset\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "1oe1x4ydbdgjmbadg003ml",
    "execution_id": "9e6c7adc-77e4-4195-9f68-8acfdb041c40",
    "id": "FZMw8kwih_Kh"
   },
   "source": [
    "Загрузка модели и токенайзера\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "cellId": "a8kb3i7u9fuwired2aherd",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5187,
     "status": "ok",
     "timestamp": 1666563848345,
     "user": {
      "displayName": "Ninja Of The Midnight",
      "userId": "05843998480307648924"
     },
     "user_tz": -180
    },
    "id": "2jx-wqYojnBb",
    "outputId": "c017898c-6c10-4560-9cc2-0cff15611af9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Errno 13] Permission denied: '/model'\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Can't load config for 'sberbank-ai/rugpt3large_based_on_gpt2'. Make sure that:\n\n- 'sberbank-ai/rugpt3large_based_on_gpt2' is a correct model identifier listed on 'https://huggingface.co/models'\n  (make sure 'sberbank-ai/rugpt3large_based_on_gpt2' is not a path to a local directory with something else, in that case)\n\n- or 'sberbank-ai/rugpt3large_based_on_gpt2' is the correct path to a directory containing a config.json file\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             resolved_config_file = cached_path(\n\u001b[0m\u001b[1;32m    567\u001b[0m                 \u001b[0mconfig_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1624\u001b[0m         \u001b[0;31m# URL, so get it from the cache (downloading if necessary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1625\u001b[0;31m         output_path = get_from_cache(\n\u001b[0m\u001b[1;32m   1626\u001b[0m             \u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m   1780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1781\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/os.py\u001b[0m in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/model'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-2fc9c68ed7f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sberbank-ai/rugpt3large_based_on_gpt2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbos_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"<s>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meos_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"<\\s>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"<pad>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"<sep>\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sberbank-ai/rugpt3large_based_on_gpt2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_token_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig_tokenizer_class\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 config = AutoConfig.from_pretrained(\n\u001b[0m\u001b[1;32m    488\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                 )\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name_or_path\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0mtrust_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trust_remote_code\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"AutoConfig\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"- or '{revision}' is a valid git identifier (branch name, a tag name, or a commit id) that exists for this model name as listed on its model page on 'https://huggingface.co/models'\\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnicodeDecodeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Can't load config for 'sberbank-ai/rugpt3large_based_on_gpt2'. Make sure that:\n\n- 'sberbank-ai/rugpt3large_based_on_gpt2' is a correct model identifier listed on 'https://huggingface.co/models'\n  (make sure 'sberbank-ai/rugpt3large_based_on_gpt2' is not a path to a local directory with something else, in that case)\n\n- or 'sberbank-ai/rugpt3large_based_on_gpt2' is the correct path to a directory containing a config.json file\n\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/rugpt3large_based_on_gpt2\", bos_token=\"<s>\", eos_token=\"<\\s>\", pad_token=\"<pad>\", sep_token=\"<sep>\", cache_dir=\"/model\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"sberbank-ai/rugpt3large_based_on_gpt2\", cache_dir=\"/model\")\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "gj8knaeab0nn0aw6wslm19",
    "execution_id": "65f61c57-d997-4201-9ae7-a32dd0aafe33",
    "id": "9I0FUfn3iN-S"
   },
   "source": [
    "Загрузка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "cellId": "cle9954xgcej4y1c8yfb9",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2193,
     "status": "ok",
     "timestamp": 1666563854342,
     "user": {
      "displayName": "Ninja Of The Midnight",
      "userId": "05843998480307648924"
     },
     "user_tz": -180
    },
    "id": "1y3ZoH5FvXrL",
    "outputId": "726060ad-d162-4ba9-bb62-cc9fc36b3391"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "df = pd.read_csv(\"Films.csv\", encoding='utf-16')\n",
    "df['Text'] = \"Название: \" + df['Title'].map(str) + \"<sep>\" + \"Описание: \" + df['Description'].map(str)\n",
    "for i in range(0, 5):\n",
    "    df['Text'] = df['Text'].apply(lambda x: str(x).replace(\"  \", \" \")[:-1])\n",
    "df['Text'] = df['Text'].apply(lambda x: str(x).replace(\"\\t\", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "8u7n4kevbvjze3c1d0f9ga",
    "execution_id": "4a5da948-b795-4887-8280-83321c7fe27f",
    "id": "MIFYj8pIiQ2b"
   },
   "source": [
    "Подготовка датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "cellId": "18nbf8tx3cal242foh3gea",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150,
     "referenced_widgets": [
      "7d4032ef1a4c49618aebda2581304aaa",
      "de7e38afa462441899ab9a26eefee187",
      "d68586f56c7345cc8c281826f065c879",
      "462705e9219c45aea8cc7e6d9efd54d3",
      "c3d6ef9c730d4b078b555b61e9ee610c",
      "6ded51349a6c4a9993c92fd5b5f5f8c5",
      "4a2d6572d1414346b5b0204364d23b08",
      "c033aec8af1e45e598bdb413fe562491",
      "69eeea800ebe444f96768ecda41dac40",
      "dbb56a6dcb6b4f09b18773f6f9a9ebb0",
      "d12496a6e2d94d5fbb6f749ad8cfc655",
      "ea5ef0cfa5624207a9db49fa3cc027bc",
      "4bfbd3137e6a433ba6999f192970c094",
      "8473d83c1dae4f038301af5876be345f",
      "0471d55af1574c4a903df8b06893fc87",
      "e934a9c1de3146d4a2d4d8a8a1d8fc2c",
      "2eb9daec748f4a7a86b6a621057fe86d",
      "5617a2261521446082fa403b61a0c2da",
      "6c839be613a84864b1bb9e158964510c",
      "59516b1b8ff14fb88e82d54e0aa7bddc",
      "367d00cfb1034047a125359e6960efa3",
      "0ad9df4a51a849f0b0724bcae115b20e"
     ]
    },
    "executionInfo": {
     "elapsed": 22853,
     "status": "ok",
     "timestamp": 1666563879328,
     "user": {
      "displayName": "Ninja Of The Midnight",
      "userId": "05843998480307648924"
     },
     "user_tz": -180
    },
    "id": "wt1FK2wzZhMO",
    "outputId": "bf47a186-f2be-4531-daca-186b35e516b5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "817da54d80914a2b9e01626675cae9af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27037 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30bda90156d4672a5e1d93e2941f5bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [1, 49639, 2235, 30, 15317, 382, 528, 3822, 5687, 50259, 630, 17408, 30, 478, 45176, 382, 528, 3822, 5687, 910, 2197, 411, 1949, 6426, 5473, 14733, 16, 5975, 289, 8597, 13818, 40638, 1258, 18, 630, 1832, 286, 807, 890, 16, 906, 4424, 19452, 30439, 1533, 3750, 41244, 779, 282, 26908, 1212, 15992, 478, 630, 2314, 17, 7530, 931, 861, 25021, 292, 685, 4618, 5258, 536, 16, 374, 282, 2615, 575, 9518, 2204, 31270, 25898, 10941, 289, 519, 4319, 1326, 5702, 2059, 411, 3322, 22290, 3314, 282, 30681, 34171, 10521, 18, 365, 5137, 4256, 333, 7310, 29257, 8445, 27147, 507, 16, 3876, 5103, 42961, 1080, 5002, 296, 1919, 282, 34781, 755, 1207, 281, 2230, 1114, 339, 2776, 298, 282, 1281, 12086, 1045, 334, 34689, 3437, 16471, 625, 18, 789, 18, 1009, 3822, 5687, 30, 478, 36382, 13725, 1135, 910, 478, 20651, 742, 403, 7729, 388, 470, 289, 478, 45176, 343, 290, 24242, 547, 4598, 763, 861, 365, 14131, 528, 3822, 5687, 282, 3106, 48185, 27734, 16, 594, 2822, 15817, 28383, 651, 34062, 354, 5772, 17, 620, 21608, 635, 16, 2438, 3215, 35552, 27448, 607, 4118, 13746, 30, 11175, 3164, 282, 38921, 18005, 1251, 1807, 35102, 289, 1807, 29050, 14974, 18, 13925, 27147, 507, 906, 590, 3290, 324, 282, 14733, 539, 520, 296, 1637, 299, 289, 1978, 798, 8562, 6520, 18, 996, 411, 17, 1567, 47781, 8121, 1033, 828, 8241, 653, 15946, 266, 16, 1053, 5735, 756, 2339, 475, 651, 360, 43987, 14733, 519, 3806, 2466, 681, 7615, 16, 32173, 29916, 289, 12502, 434, 17137, 3158, 16, 6605], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'special_tokens_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "{'input_ids': tensor([    1, 49639,  2235,    30, 15317,   382,   528,  3822,  5687, 50259,\n",
      "          630, 17408,    30,   478, 45176,   382,   528,  3822,  5687,   910,\n",
      "         2197,   411,  1949,  6426,  5473, 14733,    16,  5975,   289,  8597,\n",
      "        13818, 40638,  1258,    18,   630,  1832,   286,   807,   890,    16,\n",
      "          906,  4424, 19452, 30439,  1533,  3750, 41244,   779,   282, 26908,\n",
      "         1212, 15992,   478,   630,  2314,    17,  7530,   931,   861, 25021,\n",
      "          292,   685,  4618,  5258,   536,    16,   374,   282,  2615,   575,\n",
      "         9518,  2204, 31270, 25898, 10941,   289,   519,  4319,  1326,  5702,\n",
      "         2059,   411,  3322, 22290,  3314,   282, 30681, 34171, 10521,    18,\n",
      "          365,  5137,  4256,   333,  7310, 29257,  8445, 27147,   507,    16,\n",
      "         3876,  5103, 42961,  1080,  5002,   296,  1919,   282, 34781,   755,\n",
      "         1207,   281,  2230,  1114,   339,  2776,   298,   282,  1281, 12086,\n",
      "         1045,   334, 34689,  3437, 16471,   625,    18,   789,    18,  1009,\n",
      "         3822,  5687,    30,   478, 36382, 13725,  1135,   910,   478, 20651,\n",
      "          742,   403,  7729,   388,   470,   289,   478, 45176,   343,   290,\n",
      "        24242,   547,  4598,   763,   861,   365, 14131,   528,  3822,  5687,\n",
      "          282,  3106, 48185, 27734,    16,   594,  2822, 15817, 28383,   651,\n",
      "        34062,   354,  5772,    17,   620, 21608,   635,    16,  2438,  3215,\n",
      "        35552, 27448,   607,  4118, 13746,    30, 11175,  3164,   282, 38921,\n",
      "        18005,  1251,  1807, 35102,   289,  1807, 29050, 14974,    18, 13925,\n",
      "        27147,   507,   906,   590,  3290,   324,   282, 14733,   539,   520,\n",
      "          296,  1637,   299,   289,  1978,   798,  8562,  6520,    18,   996,\n",
      "          411,    17,  1567, 47781,  8121,  1033,   828,  8241,   653, 15946,\n",
      "          266,    16,  1053,  5735,   756,  2339,   475,   651,   360, 43987,\n",
      "        14733,   519,  3806,  2466,   681,  7615,    16, 32173, 29916,   289,\n",
      "        12502,   434, 17137,  3158,    16,  6605]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), 'special_tokens_mask': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "train_dataset = Dataset.from_pandas(df)\n",
    "def add_special_token(seq):\n",
    "    seq[\"Text\"] = '<s>' + seq[\"Text\"] + '<\\s>'\n",
    "    return seq\n",
    "train_dataset = train_dataset.map(add_special_token)\n",
    "train_dataset = train_dataset.remove_columns(['Title', 'Description'])\n",
    "def encode(examples):\n",
    "    return tokenizer(examples['Text'], padding='max_length', max_length=256, truncation=True, return_special_tokens_mask=True,)  \n",
    "train_dataset = train_dataset.map(encode, batched=True, remove_columns=[\"Text\"])\n",
    "print(train_dataset[19634])\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"special_tokens_mask\"])\n",
    "print(train_dataset[19634])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "cellId": "3dm1kq6ifpgbv9r7h6w9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'Наз', 'вание', ':', ' Сказ', 'ки', ' Г', 'оф', 'мана', '<sep>', 'О', 'писание', ':', ' «', 'Сказ', 'ки', ' Г', 'оф', 'мана', '»,', ' одна', ' из', ' двух', ' роман', 'тических', ' опер', ',', ' последнее', ' и', ' незакон', 'ченное', ' сочинение', ' Ж', '.', 'О', 'фф', 'ен', 'ба', 'ха', ',', ' была', ' впервые', ' представлена', ' публике', ' 10', ' февраля', ' 1881', ' года', ' в', ' париж', 'ском', ' театре', ' «', 'О', 'пера', '-', 'Ком', 'ик', '».', ' Успе', 'х', ' был', ' настолько', ' шум', 'ным', ',', ' что', ' в', ' первый', ' же', ' сезон', ' опера', ' выдержала', ' 101', ' представление', ' и', ' до', ' сих', ' пор', ' остается', ' одной', ' из', ' самых', ' востребов', 'анных', ' в', ' мировом', ' реперту', 'аре', '.', ' В', ' основе', ' пяти', 'ак', 'тной', ' оперы', ' лежит', ' пье', 'са', ',', ' напис', 'анная', ' Жю', 'лем', ' Бар', 'б', 'ье', ' в', ' соав', 'тор', 'стве', ' с', ' Ми', 'шел', 'ем', ' Кар', 'ре', ' в', ' 18', '51', ' году', ' по', ' мотивам', ' трех', ' произведений', ' Э', '.', 'Т', '.', 'Г', 'оф', 'мана', ':', ' «', 'Пес', 'очный', ' человек', '»,', ' «', 'Совет', 'ник', ' К', 'респ', 'ель', '»', ' и', ' «', 'Сказ', 'ка', ' о', ' потерян', 'ном', ' изображ', 'ении', '».', ' В', 'ведение', ' Г', 'оф', 'мана', ' в', ' качестве', ' самостоятельного', ' персонажа', ',', ' ста', 'вшего', ' собственным', ' героем', ' –', 'меч', 'та', 'телем', '-', 'ром', 'анти', 'ком', ',', ' стало', ' довольно', ' неожиданным', ' драматур', 'ги', 'ческим', ' шагом', ':', ' герой', ' находится', ' в', ' постоянном', ' движении', ' между', ' собой', ' реальным', ' и', ' собой', ' вообража', 'емым', '.', ' Позже', ' пье', 'са', ' была', ' пере', 'работа', 'на', ' в', ' опер', 'ное', ' ли', 'б', 'рет', 'то', ' и', ' предлож', 'ена', ' компози', 'тору', '.', ' Так', ' из', '-', 'под', ' пера', ' автора', ' более', ' чем', ' сотни', ' оп', 'ерет', 'т', ',', ' пар', 'оди', 'рова', 'вших', ' все', ' –', ' от', ' классических', ' опер', ' до', ' анти', 'чных', ' ми', 'фов', ',', ' христианской', ' морали', ' и', ' газет', 'ного', ' офици', 'оза', ',', ' появилась']\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "print([tokenizer.decode(x) for x in train_dataset[19634]['input_ids']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "rrxfxy12cqqdvwsr5u43tp",
    "execution_id": "66e4caad-8c08-4097-83cf-2ca14d5ec938",
    "id": "_KbmpC8TiTqV"
   },
   "source": [
    "Задание параметров обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "cellId": "mscbx6y3tib67z1tyssyn",
    "executionInfo": {
     "elapsed": 7694,
     "status": "ok",
     "timestamp": 1666563938913,
     "user": {
      "displayName": "Ninja Of The Midnight",
      "userId": "05843998480307648924"
     },
     "user_tz": -180
    },
    "id": "bEJryCD4a6yK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This tokenizer does not have a mask token which is necessary for masked language modeling. You should pass `mlm=False` to train on causal language modeling instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fdc6b187fad7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#pragma async\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_collator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataCollatorForLanguageModeling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m training_args = TrainingArguments(\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"/home/jupyter/mnt/s3/model-output\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tokenizer, mlm, mlm_probability, pad_to_multiple_of, tf_experimental_compile, return_tensors)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36m__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    636\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__post_init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlm\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask_token\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    639\u001b[0m                 \u001b[0;34m\"This tokenizer does not have a mask token which is necessary for masked language modeling. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0;34m\"You should pass `mlm=False` to train on causal language modeling instead.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This tokenizer does not have a mask token which is necessary for masked language modeling. You should pass `mlm=False` to train on causal language modeling instead."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background cell scheduled. Waiting for foreground cells to finish commits\n",
      "Preparing g1.1 instance...\n",
      "g1.1 instance is ready, running task...\n",
      "Task is done, waiting for foreground cells to finish...\n",
      "Merging task result to the state\n"
     ]
    }
   ],
   "source": [
    "#!g1.1\n",
    "#pragma async\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=True)\n",
    "training_args = TrainingArguments(\n",
    "    \"/home/jupyter/mnt/s3/model-output\",\n",
    "    num_train_epochs=30,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=16,\n",
    "    warmup_steps=10,\n",
    "    weight_decay=0.05\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset, \n",
    "    optimizers = (torch.optim.AdamW(model.parameters(),lr=1e-5),None)\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "cellId": "hbpxlgnoovv38flf8w00ts"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>Название: Плохие парни\\nОписание:  В центре сюжета фильма«Плохие парни»—необычная история, которая разворачивается впригородной деревушке, гдепроисходит множество загадочных инепредсказуемых событий. Вэтом таинственном месте живут иживут трое главных героев, каждый изних по-своему, новсе они—плохие парни. Вцентре сюжета фильма«Плохие парни»—необычная история, которая разворачивается впригородной деревушке, гдепроисходит множество загадочных инепредсказуемых событий. Вэтом таинственном месте живут иживут трое главных героев, каждый изних по-своему, новсе они—плохие парни. Вцентре сюжета картины«Плохие парни»—необычная история, которая разворачивается впригородной деревушке, гдепроисходит множество загадочных инепредсказуемых событий. Вэтом таинственном месте живут иживут трое главных героев, каждый изних по-своему, новсе они—плохие парни. Вцентре сюжета фильма«Плохие парни»—необычная история, которая разворачивается впригородной деревушке, гдепроисходит множество загадочных']\n"
     ]
    }
   ],
   "source": [
    "text = \"<s>Название: Американский огузок\\n\"\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model.generate(input_ids, \n",
    "                        do_sample=True,\n",
    "                        num_beams=2,\n",
    "                        temperature=1.5,\n",
    "                        top_p=0.9,\n",
    "                        max_length=512\n",
    "                        )\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print()\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "vt5czkeumi7fj156cmh7b"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "a36906ec-0e70-479b-af65-7f4d80c75160",
  "notebookPath": "oop.ipynb",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0471d55af1574c4a903df8b06893fc87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_367d00cfb1034047a125359e6960efa3",
      "placeholder": "​",
      "style": "IPY_MODEL_0ad9df4a51a849f0b0724bcae115b20e",
      "value": " 27/28 [00:19&lt;00:01,  1.24s/ba]"
     }
    },
    "0ad9df4a51a849f0b0724bcae115b20e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2eb9daec748f4a7a86b6a621057fe86d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "367d00cfb1034047a125359e6960efa3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "462705e9219c45aea8cc7e6d9efd54d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dbb56a6dcb6b4f09b18773f6f9a9ebb0",
      "placeholder": "​",
      "style": "IPY_MODEL_d12496a6e2d94d5fbb6f749ad8cfc655",
      "value": " 27037/27037 [00:02&lt;00:00, 11998.30ex/s]"
     }
    },
    "4a2d6572d1414346b5b0204364d23b08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4bfbd3137e6a433ba6999f192970c094": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2eb9daec748f4a7a86b6a621057fe86d",
      "placeholder": "​",
      "style": "IPY_MODEL_5617a2261521446082fa403b61a0c2da",
      "value": " 96%"
     }
    },
    "5617a2261521446082fa403b61a0c2da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "59516b1b8ff14fb88e82d54e0aa7bddc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "69eeea800ebe444f96768ecda41dac40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6c839be613a84864b1bb9e158964510c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ded51349a6c4a9993c92fd5b5f5f8c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d4032ef1a4c49618aebda2581304aaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_de7e38afa462441899ab9a26eefee187",
       "IPY_MODEL_d68586f56c7345cc8c281826f065c879",
       "IPY_MODEL_462705e9219c45aea8cc7e6d9efd54d3"
      ],
      "layout": "IPY_MODEL_c3d6ef9c730d4b078b555b61e9ee610c"
     }
    },
    "8473d83c1dae4f038301af5876be345f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c839be613a84864b1bb9e158964510c",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_59516b1b8ff14fb88e82d54e0aa7bddc",
      "value": 27
     }
    },
    "c033aec8af1e45e598bdb413fe562491": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c3d6ef9c730d4b078b555b61e9ee610c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d12496a6e2d94d5fbb6f749ad8cfc655": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d68586f56c7345cc8c281826f065c879": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c033aec8af1e45e598bdb413fe562491",
      "max": 27037,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_69eeea800ebe444f96768ecda41dac40",
      "value": 27037
     }
    },
    "dbb56a6dcb6b4f09b18773f6f9a9ebb0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de7e38afa462441899ab9a26eefee187": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ded51349a6c4a9993c92fd5b5f5f8c5",
      "placeholder": "​",
      "style": "IPY_MODEL_4a2d6572d1414346b5b0204364d23b08",
      "value": "100%"
     }
    },
    "e934a9c1de3146d4a2d4d8a8a1d8fc2c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ea5ef0cfa5624207a9db49fa3cc027bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4bfbd3137e6a433ba6999f192970c094",
       "IPY_MODEL_8473d83c1dae4f038301af5876be345f",
       "IPY_MODEL_0471d55af1574c4a903df8b06893fc87"
      ],
      "layout": "IPY_MODEL_e934a9c1de3146d4a2d4d8a8a1d8fc2c"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
